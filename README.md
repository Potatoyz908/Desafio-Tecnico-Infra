# Desafio TÃ©cnico â€” Ambiente de Desenvolvimento para Engenharia de Dados

[![Docker](https://img.shields.io/badge/Docker-2496ED?style=flat&logo=docker&logoColor=white)](https://www.docker.com/)
[![Airflow](https://img.shields.io/badge/Apache%20Airflow-017CEE?style=flat&logo=apache-airflow&logoColor=white)](https://airflow.apache.org/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-316192?style=flat&logo=postgresql&logoColor=white)](https://www.postgresql.org/)
[![Superset](https://img.shields.io/badge/Apache%20Superset-20A6C9?style=flat&logo=apache&logoColor=white)](https://superset.apache.org/)

## ğŸ“‹ SumÃ¡rio
- [Objetivo](#-objetivo)
- [Arquitetura](#-arquitetura)
- [Ferramentas](#-ferramentas)
- [PrÃ©-requisitos](#-prÃ©-requisitos)
- [Como Executar](#-como-executar)
- [ValidaÃ§Ã£o e Testes](#-validaÃ§Ã£o-e-testes)
- [Interoperabilidade](#-interoperabilidade)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [SeguranÃ§a](#-seguranÃ§a)
- [Troubleshooting](#-troubleshooting)

## ğŸ¯ Objetivo

Este projeto demonstra a criaÃ§Ã£o de um ambiente de desenvolvimento completo para Engenharia de Dados, com foco em:

- **PadronizaÃ§Ã£o**: Ambiente reproduzÃ­vel via Docker Compose
- **SeguranÃ§a**: Credenciais gerenciadas via variÃ¡veis de ambiente
- **Interoperabilidade**: IntegraÃ§Ã£o funcional entre todas as ferramentas
- **Simplicidade**: ConfiguraÃ§Ã£o enxuta e focada no essencial

## ğŸ— Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AMBIENTE DE DADOS                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   AIRFLOW    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚       POSTGRES           â”‚      â”‚
â”‚  â”‚              â”‚         â”‚                          â”‚      â”‚
â”‚  â”‚  - Webserver â”‚         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚      â”‚
â”‚  â”‚  - Scheduler â”‚         â”‚  â”‚ airflow_meta       â”‚  â”‚      â”‚
â”‚  â”‚  - Init      â”‚         â”‚  â”‚ (Metadados Airflow)â”‚  â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚      â”‚
â”‚       :8080               â”‚                          â”‚      â”‚
â”‚                           â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚  â”‚ superset_meta      â”‚  â”‚      â”‚
â”‚  â”‚   SUPERSET   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  â”‚(Metadados Superset)â”‚  â”‚      â”‚
â”‚  â”‚              â”‚         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚      â”‚
â”‚  â”‚  - WebUI     â”‚         â”‚                          â”‚      â”‚
â”‚  â”‚  - Init      â”‚         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚  â”‚ analytics          â”‚  â”‚      â”‚
â”‚       :8088               â”‚  â”‚ (Data Warehouse)   â”‚  â”‚      â”‚
â”‚                           â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚      â”‚
â”‚                           â”‚                          â”‚      â”‚
â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                    :5432                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ›  Ferramentas

### Apache Airflow (v2.7.3)
- **FunÃ§Ã£o**: Orquestrador de workflows de dados (DAGs)
- **Executor**: LocalExecutor
- **Metadados**: PostgreSQL (database `airflow_meta`)
- **Interface**: http://localhost:8080

### PostgreSQL (v15)
- **FunÃ§Ã£o**: Database relacional multipropÃ³sito
- **Databases**:
  - `airflow_meta`: Metadados do Airflow
  - `superset_meta`: Metadados do Superset
  - `analytics`: Data Warehouse para anÃ¡lises
- **Porta**: 5432

### Apache Superset (v3.0.1)
- **FunÃ§Ã£o**: Plataforma de BI e visualizaÃ§Ã£o de dados
- **Metadados**: PostgreSQL (database `superset_meta`)
- **Fonte de Dados**: PostgreSQL (database `analytics`)
- **Interface**: http://localhost:8088

## ğŸ“¦ PrÃ©-requisitos

- **Docker**: versÃ£o 20.10 ou superior
- **Docker Compose**: versÃ£o 2.0 ou superior
- **Hardware mÃ­nimo recomendado**:
  - 8 GB RAM
  - 4 CPU cores
  - 10 GB espaÃ§o em disco

## ğŸš€ Como Executar

### 1. Clonar o RepositÃ³rio

```bash
git clone <url-do-repositorio>
cd Desafio-Tecnico-Infra
```

### 2. Configurar VariÃ¡veis de Ambiente

```bash
# Copiar o arquivo de exemplo
cp .env.example .env

# Gerar Fernet Key para o Airflow (opcional, mas recomendado)
python3 -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"

# Editar o .env e substituir as chaves geradas
nano .env  # ou use seu editor preferido
```

**Importante**: Nunca versione o arquivo `.env` com credenciais reais!

### 3. Subir o Ambiente

```bash
# Subir todos os serviÃ§os
docker-compose up -d

# Acompanhar os logs (opcional)
docker-compose logs -f
```

### 4. Aguardar InicializaÃ§Ã£o

Os serviÃ§os podem levar de 2 a 5 minutos para inicializar completamente. VocÃª pode monitorar o status:

```bash
# Verificar status dos containers
docker-compose ps

# Verificar logs de um serviÃ§o especÃ­fico
docker-compose logs airflow-init
docker-compose logs superset-init
```

## âœ… ValidaÃ§Ã£o e Testes

### 1. Verificar Postgres

```bash
# Conectar ao Postgres
docker exec -it postgres psql -U postgres

# Dentro do psql, listar databases
\l

# VocÃª deve ver: airflow_meta, superset_meta e analytics
```

**O que observar**: Os trÃªs databases devem estar criados e ativos.

### 2. Acessar Airflow

1. Abrir navegador: http://localhost:8080
2. **Credenciais** (conforme `.env`):
   - UsuÃ¡rio: `admin`
   - Senha: `admin`

**O que observar**:
- Interface do Airflow carregada
- Menu "Admin" > "Connections" acessÃ­vel
- DAG `exemplo_airflow_postgres` aparece na lista

### 3. Configurar Connection no Airflow

Para demonstrar a interoperabilidade Airflow â†’ Postgres:

1. No Airflow, ir em **Admin** > **Connections**
2. Clicar em **[+]** (adicionar nova conexÃ£o)
3. Preencher:
   - **Connection Id**: `postgres_analytics`
   - **Connection Type**: `Postgres`
   - **Host**: `postgres`
   - **Schema**: `analytics`
   - **Login**: `analytics_user`
   - **Password**: `analytics_password`
   - **Port**: `5432`
4. Clicar em **Test** (botÃ£o inferior)
5. **EVIDÃŠNCIA OBRIGATÃ“RIA**: Capturar print da mensagem de sucesso do teste

**O que observar**: Mensagem verde confirmando "Connection successfully tested".

### 4. Executar DAG de Exemplo

1. Na interface do Airflow, localizar a DAG `exemplo_airflow_postgres`
2. Ativar a DAG (toggle no canto esquerdo)
3. Clicar no Ã­cone de "play" para executar manualmente
4. Acompanhar a execuÃ§Ã£o das tasks no Graph View
5. Verificar logs de cada task

**O que observar**:
- Todas as tasks devem executar com sucesso (verde)
- A task `check_connection` confirma conexÃ£o com Postgres
- A task `create_table` cria a tabela `exemplo_vendas`
- A task `insert_sample_data` insere dados
- A task `query_data` exibe os dados inseridos nos logs

### 5. Acessar Superset

1. Abrir navegador: http://localhost:8088
2. **Credenciais** (conforme `.env`):
   - UsuÃ¡rio: `admin`
   - Senha: `admin`

**O que observar**: Interface do Superset carregada com sucesso.

### 6. Configurar Database no Superset

Para demonstrar a interoperabilidade Superset â†’ Postgres:

1. No Superset, ir em **Settings** > **Database Connections**
2. Clicar em **+ Database**
3. Selecionar **PostgreSQL**
4. Preencher na aba **SQLALCHEMY URI**:
   ```
   postgresql://analytics_user:analytics_password@postgres:5432/analytics
   ```
5. Dar um nome (ex: "Analytics Warehouse")
6. Clicar em **Test Connection**
7. **EVIDÃŠNCIA OBRIGATÃ“RIA**: Capturar print da mensagem de sucesso
8. Salvar a conexÃ£o

**O que observar**: Mensagem de sucesso confirmando conexÃ£o com o database `analytics`.

### 7. Criar SQL Query no Superset

Para validar que o Superset consegue consultar os dados criados pelo Airflow:

1. Ir em **SQL** > **SQL Lab**
2. Selecionar o database "Analytics Warehouse"
3. Executar a query:
   ```sql
   SELECT * FROM exemplo_vendas;
   ```

**O que observar**: Dados inseridos pela DAG do Airflow devem ser exibidos.

## ğŸ”— Interoperabilidade

### âœ… Airflow â†” Postgres
- **Tipo**: GravaÃ§Ã£o e consulta SQL
- **ComprovaÃ§Ã£o**: 
  - Connection testada com sucesso no Airflow
  - DAG executa operaÃ§Ãµes no database `analytics`
  - Dados persistidos e consultÃ¡veis

### âœ… Superset â†” Postgres
- **Tipo**: Consulta SQL e visualizaÃ§Ã£o
- **ComprovaÃ§Ã£o**:
  - Database connection testada com sucesso
  - Consultas executadas no SQL Lab
  - Dados do Airflow visÃ­veis no Superset

### ğŸ“Š Fluxo Completo
```
Airflow DAG â†’ Cria tabela no Postgres (analytics)
           â†’ Insere dados no Postgres (analytics)
           â†’ Superset consulta dados do Postgres (analytics)
           â†’ VisualizaÃ§Ã£o no Superset
```

## ğŸ“ Estrutura do Projeto

```
Desafio-Tecnico-Infra/
â”œâ”€â”€ docker-compose.yml          # OrquestraÃ§Ã£o dos containers
â”œâ”€â”€ .env.example                # Template de variÃ¡veis (SEM credenciais)
â”œâ”€â”€ .gitignore                  # Ignora credenciais e dados sensÃ­veis
â”œâ”€â”€ README.md                   # Esta documentaÃ§Ã£o
â”‚
â”œâ”€â”€ postgres/
â”‚   â””â”€â”€ init/
â”‚       â””â”€â”€ 01-init-databases.sql  # Script de inicializaÃ§Ã£o do Postgres
â”‚
â”œâ”€â”€ airflow/
â”‚   â””â”€â”€ dags/
â”‚       â””â”€â”€ exemplo_airflow_postgres.py  # DAG de demonstraÃ§Ã£o
â”‚
â””â”€â”€ evidencias/                 # Pasta para prints de validaÃ§Ã£o
    â”œâ”€â”€ airflow-connection-test.png
    â””â”€â”€ superset-connection-test.png
```

## ğŸ”’ SeguranÃ§a

### PrÃ¡ticas Implementadas

âœ… **VariÃ¡veis de ambiente**: Todas as credenciais em `.env`  
âœ… **Gitignore configurado**: Arquivo `.env` nunca versionado  
âœ… **Template pÃºblico**: `.env.example` sem dados sensÃ­veis  
âœ… **SegregaÃ§Ã£o de roles**: Cada serviÃ§o tem seu prÃ³prio usuÃ¡rio no Postgres  
âœ… **PermissÃµes mÃ­nimas**: UsuÃ¡rios com acesso apenas aos databases necessÃ¡rios

### RecomendaÃ§Ãµes para ProduÃ§Ã£o

âš ï¸ Este ambiente Ã© para **desenvolvimento local** apenas. Para produÃ§Ã£o:

- Usar secrets managers (AWS Secrets Manager, Vault, etc)
- Implementar TLS/SSL para conexÃµes
- Configurar autenticaÃ§Ã£o via LDAP/OAuth
- Implementar backup automatizado
- Usar imagens Docker customizadas e verificadas
- Aplicar hardening nos containers

## ğŸ› Troubleshooting

### ServiÃ§os nÃ£o sobem

```bash
# Verificar logs de erro
docker-compose logs

# Recriar volumes e containers
docker-compose down -v
docker-compose up -d
```

### Airflow nÃ£o inicializa

```bash
# Verificar logs do init
docker-compose logs airflow-init

# Garantir que Postgres estÃ¡ saudÃ¡vel
docker-compose ps postgres
```

### Superset nÃ£o conecta ao Postgres

- Verificar se o driver `psycopg2` estÃ¡ instalado na imagem
- Confirmar que o database `analytics` foi criado
- Validar credenciais no `.env`

### Porta jÃ¡ em uso

Se alguma porta (5432, 8080, 8088) jÃ¡ estiver em uso:

1. Editar `docker-compose.yml`
2. Alterar o mapeamento de portas (ex: `"8081:8080"`)
3. Recriar os containers

## ğŸ“¸ EvidÃªncias

As evidÃªncias obrigatÃ³rias foram salvas na pasta `evidencias/`:

1. **airflow-connection-test.png**: Print do teste de conexÃ£o bem-sucedido no Airflow
2. **superset-connection-test.png**: Print do teste de conexÃ£o bem-sucedido no Superset

## ğŸ“ DecisÃµes TÃ©cnicas

### Por que LocalExecutor?
- Simplicidade para ambiente de desenvolvimento
- NÃ£o requer Celery/Redis adicional
- Suficiente para testes e validaÃ§Ãµes

### Por que um Ãºnico Postgres?
- Economia de recursos
- Simplifica gerenciamento
- SegregaÃ§Ã£o via databases e roles
- PadrÃ£o comum em ambientes de desenvolvimento

### Por que estas versÃµes?
- **Airflow 2.7.3**: VersÃ£o estÃ¡vel e amplamente usada
- **Postgres 15**: Balance entre features e estabilidade
- **Superset 3.0.1**: VersÃ£o recente com melhorias de UX

## ğŸ“„ LicenÃ§a

Este projeto Ã© disponibilizado para fins educacionais e de avaliaÃ§Ã£o tÃ©cnica.

## ğŸ‘¤ Autor

**Euller JÃºlio**  
GitHub: [@Potatoyz908](https://github.com/Potatoyz908)

---

**Desafio Stack Dados 2025** | Entregue em 17/10/2025
